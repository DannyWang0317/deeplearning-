import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader, Dataset
import os
import numpy as np
from PIL import Image
from tqdm import tqdm
import matplotlib.pyplot as plt
import time

# 設定資料路徑
train_file = "C:\\Users\\NCKU-BAISP\\Desktop\\dl\\homework4\\train.txt"
val_file = "C:\\Users\\NCKU-BAISP\\Desktop\\dl\\homework4\\val.txt"
test_file = "C:\\Users\\NCKU-BAISP\\Desktop\\dl\\homework4\\test.txt"
images_folder = "C:\\Users\\NCKU-BAISP\\Desktop\\dl\\homework4"

# 定義RRDB模塊
class RRDB(nn.Module):
    def __init__(self, in_channels, growth_channels):
        super(RRDB, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, growth_channels, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(growth_channels, growth_channels, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(growth_channels, in_channels, kernel_size=3, padding=1)
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        residual = x
        out = self.relu(self.conv1(x))
        out = self.relu(self.conv2(out))
        out = self.conv3(out)
        return out + residual

# 定義自注意力機制
class SelfAttention(nn.Module):
    def __init__(self, in_channels):
        super(SelfAttention, self).__init__()
        self.query = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)
        self.key = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)
        self.value = nn.Conv2d(in_channels, in_channels, kernel_size=1)
        self.gamma = nn.Parameter(torch.zeros(1))

    def forward(self, x):
        batch_size, C, width, height = x.size()
        query = self.query(x).view(batch_size, -1, width * height).permute(0, 2, 1)
        key = self.key(x).view(batch_size, -1, width * height)
        energy = torch.bmm(query, key)
        attention = torch.softmax(energy, dim=-1)
        value = self.value(x).view(batch_size, -1, width * height)

        out = torch.bmm(value, attention.permute(0, 2, 1))
        out = out.view(batch_size, C, width, height)

        out = self.gamma * out + x
        return out

# 定義兩層CNN模型
class TwoLayerCNN(nn.Module):
    def __init__(self, num_classes):
        super(TwoLayerCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)
        self.rrdb1 = RRDB(in_channels=64, growth_channels=64)
        self.attention1 = SelfAttention(in_channels=64)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.rrdb2 = RRDB(in_channels=64, growth_channels=64)
        self.attention2 = SelfAttention(in_channels=64)
        self.fc = nn.Linear(64 * 8 * 8, num_classes)  # 假設輸入圖像調整為32x32

    def forward(self, x):
        x = self.conv1(x)
        x = self.pool(self.attention1(self.rrdb1(x)))
        x = self.pool(self.attention2(self.rrdb2(x)))
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x

# 自定義Dataset類別以讀取數據
class CustomDataset(Dataset):
    def __init__(self, txt_file, img_dir, transform=None):
        self.img_labels = np.loadtxt(txt_file, dtype=str)
        self.img_dir = img_dir
        self.transform = transform

    def __len__(self):
        return len(self.img_labels)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.img_labels[idx, 0].replace('\\', '/'))
        image = Image.open(img_path).convert("RGB")
        label = int(self.img_labels[idx, 1])
        if self.transform:
            image = self.transform(image)
        return image, label

# 定義圖像轉換
transform = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
])

# 讀取資料集
train_dataset = CustomDataset(txt_file=train_file, img_dir=images_folder, transform=transform)
val_dataset = CustomDataset(txt_file=val_file, img_dir=images_folder, transform=transform)
test_dataset = CustomDataset(txt_file=test_file, img_dir=images_folder, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# 訓練模型函數
def train_model(model, train_loader, val_loader, num_epochs=10):
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    train_accuracies = []
    val_accuracies = []

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        correct_train = 0
        total_train = 0
        start_time = time.time()
        for images, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}"):
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            total_train += labels.size(0)
            correct_train += (predicted == labels).sum().item()
        
        train_accuracies.append(100 * correct_train / total_train)

        end_time = time.time()
        train_time = end_time - start_time

        model.eval()
        val_loss = 0.0
        correct_val = 0
        total_val = 0
        with torch.no_grad():
            for images, labels in tqdm(val_loader, desc="Validating"):
                outputs = model(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item()
                _, predicted = torch.max(outputs, 1)
                total_val += labels.size(0)
                correct_val += (predicted == labels).sum().item()
        
        val_accuracies.append(100 * correct_val / total_val)

        print(f"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}, Val Loss: {val_loss/len(val_loader)}, Val Accuracy: {100 * correct_val / total_val}%, Train Time: {train_time:.2f}s")
    
    return train_accuracies, val_accuracies

# 測試模型函數
def test_model(model, test_loader):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in tqdm(test_loader, desc="Testing"):
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    
    print(f"Test Accuracy: {100 * correct / total}%")

# 繪製準確率曲線
def plot_accuracy_curve(train_acc1, val_acc1, train_acc2, val_acc2):
    epochs = range(1, len(train_acc1) + 1)
    plt.plot(epochs, train_acc1, 'b', label='TwoLayerCNN Train Accuracy')
    plt.plot(epochs, val_acc1, 'r', label='TwoLayerCNN Val Accuracy')
    plt.plot(epochs, train_acc2, 'g', label='ResNet34 Train Accuracy')
    plt.plot(epochs, val_acc2, 'y', label='ResNet34 Val Accuracy')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.show()

# 初始化和訓練兩層CNN模型
num_classes = 50  # 假設有50個類別
model = TwoLayerCNN(num_classes=num_classes)
cnn_train_acc, cnn_val_acc = train_model(model, train_loader, val_loader, num_epochs=10)
test_model(model, test_loader)

# 初始化和訓練ResNet34模型
resnet_model = models.resnet34(pretrained=False, num_classes=num_classes)
resnet_train_acc, resnet_val_acc = train_model(resnet_model, train_loader, val_loader, num_epochs=10)
test_model(resnet_model, test_loader)

# 繪製準確率曲線
plot_accuracy_curve(cnn_train_acc, cnn_val_acc, resnet_train_acc, resnet_val_acc)
